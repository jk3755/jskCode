---
title: "TCGAatac"
author: "Jordan S. Kesner"
date: "1/5/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

Packages
```{r, echo = FALSE}
#source("https://bioconductor.org/biocLite.R")
#biocLite("rtracklayer", suppressUpdates = TRUE)
#biocLite("GenomicRanges", suppressUpdates = TRUE)
#biocLite("BSgenome.Hsapiens.UCSC.hg38", suppressUpdates = TRUE)
#biocLite("Repitools", suppressUpdates = TRUE)
#biocLite("genomation", suppressUpdates = TRUE)
#biocLite("Rsamtools", suppressUpdates = TRUE)
#install.packages("progress")
library(rtracklayer)
library(GenomicRanges)
library(GenomicAlignments)
library(BSgenome.Hsapiens.UCSC.hg38)
library(Repitools)
library(Rsamtools)
library(genomation)
library(tcltk)
library(progress)
```


Get filepaths of interest
```{r}

path <- "/home/ubuntu2/atac/gdc/bigwig/COAD/"
paths <- paste0(path, list.files("/home/ubuntu2/atac/gdc/bigwig/COAD/", pattern = ".bw"))

# set N or the number of files to import
n <- length(paths)

```


Import TCGA files
```{r}

#### Initialize list object to hold imported files
coad_gr <- list()


#### Initialize progress bar
pb <- progress_bar$new(total = n)


#### Loop import all the bigwig files
for (i in 1:n)
  {
  # update progress bar
  pb$tick()
  flush.console() 

  # eval/parse to import all files
  command <- paste0("coad_gr[", i, "] <- rtracklayer::import(BigWigFile(paths[", i,"]))")
  eval(parse(text = command))
  } # end for (i in 1:n)


#### Loop subset all the imported Granges for chr1 only
coad_gr_chr1 <- list()
pb <- progress_bar$new(
  format = "  downloading [:bar] :percent in :elapsed",
  total = n, clear = FALSE, width= 60)

for (a in 1:n)
  {
  # update progress bar
  pb$tick()
  flush.console()  
  
  idx <- which(coad_gr[[a]]@seqnames == "chr1")
  coad_gr_chr1[[a]] <- coad_gr[[a]][idx]
  } # end for (a in 1:length(coad_gr))

```


Initialize binned Granges
```{r}

make.windows = function(binsize)
{bins = tileGenome(seqinfo(Hsapiens), tilewidth = binsize, 
                  cut.last.tile.in.chrom = TRUE)
return(bins)}

####
basecount = function(windows, data, chrlist)
{
    # this is an instance of the general basecount function that takes as input 
    # a set of bins (in GRanges format), a GRanges object containing count data,
    # and a list of chromosomes of interest. It returns a GRanges object 
    # identical to the input bins, with a score column indicating the average 
    # number of instances where a feature in the count data was present within 
    # the bin. It does not normalize to anything.
	require(GenomicRanges)
	require(GenomicAlignments)
    
	binnedAverage = function(bins,numvar)
	{
		stopifnot(is(bins, "GRanges"))
		stopifnot(is(numvar, "RleList"))
		stopifnot(identical(seqlevels(bins), names(numvar)))
		bins_per_chrom = split(ranges(bins), seqnames(bins))
		means_list = lapply(names(numvar),
			function(seqname){
				views = Views(numvar[[seqname]],
				bins_per_chrom[[seqname]])
			viewMeans(views)	
			})
		new_mcol = unsplit( means_list, as.factor( seqnames( bins)))
		mcols( bins)[['basecount']] = new_mcol
		bins
	}
		
	good.uns = chrlist
	windows = windows[seqnames( windows) %in% good.uns]
	seqlevels( windows) = seqlevelsInUse( windows)
	cov = coverage( data)
	cov = cov[match( seqlevels( windows),names( cov))]
	
	bcount = binnedAverage( windows, cov)
	bcount = mcols( bcount)[,1]
	score( windows) = bcount
	return( windows)
}

####

#### Define a string for selecting which chromosomes youre interested in
good.uns = c( 'chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10','chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19','chr20','chr21','chr22','chrX','chrY')

#### Generate 100 bp windows across hg38 genome
genome.windows = make.windows(binsize = 100) # increase the bin size for hg38 to deal with memory issues

# shift all the windows back by 1 bp to match the TCGA annotations
genome.windows@ranges@start <- as.integer((genome.windows@ranges@start - 1))

# initialize 
tcga_coad_avg <- genome.windows

# start off with just chr1
idx <- which(tcga_coad_avg@seqnames == "chr1")
tcga_coad_avg_chr1 <- tcga_coad_avg[idx]

```


The important loop - updating values with TCGA COAD average
```{r}

# Verbosity option
v <- TRUE
num <- length(tcga_coad_avg_chr1)
tnum <- length(coad_gr_chr1)

## Progress bar with elapsed time
pb <- progress_bar$new(
  format = "  Processing [:bar] :percent in :elapsed",
  total = num, clear = FALSE, width= 60)


#
if (v == TRUE){
  cat("Found ", num, "genomic bins", "\n")
  cat("Found ", tnum, "samples to match against", "\n")
}

for (b in 1:num){
  
  ## Progress bar
  # pb$tick()
  #flush.console()
  
  ## Initialize matrix to store matches
  idx <- matrix(data = 0, nrow = 4, ncol = tnum)
  tomatch <- tcga_coad_avg_chr1@ranges@start[b]
  
  ## Report
  if (v == TRUE){
    cat("Current bin index: ", b, "\n")
    cat("Current matrix contents: ", "\n")
    cat(idx[1,], "\n")
    cat(idx[2,], "\n")
    cat(idx[3,], "\n")
    cat(idx[4,], "\n")
    cat("Current bin start position: ", tomatch, "\n")
  }
  
  ## Loop through matching samples
  for (m in 1:tnum){
    
    matched <- length(which(coad_gr_chr1[[m]]@ranges@start == tomatch))
    id <- which(coad_gr_chr1[[m]]@ranges@start == tomatch)
    
    ## Reporting
    if (v == TRUE){
      cat("Current sample index: ", m, "\n")
      cat("Matching results : ", matched, "\n")
      #
      if (matched != 0){
        cat("A match was found in sample: ", m, "\n", "The start position of this match is: ", coad_gr_chr1[[m]]@ranges@start[id], "\n")
      }} # end Reporting
    
    ## If no match was made, matrix values are set at 0
    if (matched == 0){
      
      #
      #cat("Setting matrix values to 0 for sample: ", m, "\n")
      idx[1,m] <- 0
      idx[2,m] <- 0
      
    }
    
    ## If a match was made, input the sample number and index of the match to the matrix
    if (matched != 0){
      
      #
      #cat("Setting matrix values for sample : ", m, "\n", "at index: ", id, "\n")
      idx[1,m] <- m 
      idx[2,m] <- id
    }
  } # end for (m in 1:tnum)
  
  ## Reporting
    if (v == TRUE){
      cat("Current matrix contents: ", "\n")
      cat(idx[1,], "\n")
      cat(idx[2,], "\n")
      cat(idx[3,], "\n")
      cat(idx[4,], "\n")
    }
  
  ## Collect matched values and confirm start positions
  for (k in 1:tnum){
    
    if (idx[1,k] == 0){
      next
    }
    if (idx[1,k] != 0){
      idx[3,k] <- coad_gr_chr1[[idx[1,k]]]@ranges@start[idx[2,k]]
      idx[4,k] <- coad_gr_chr1[[idx[1,k]]]@elementMetadata@listData[["score"]][idx[2,k]]
    }
  } # end for (k in 1:tnum)
  
  if (v == TRUE){
  cat("Final matrix contents:", "\n")
  cat(idx[1,], "\n")
  cat(idx[2,], "\n")
  cat(idx[3,], "\n")
  cat(idx[4,], "\n")}
  
  aa <- which(idx[1,] != 0)
  nummatch <- length(aa)
  ab <- sum(idx[4,])
  ac <- ab/nummatch
  
  if (v == TRUE)
    {
    cat("\n")
    cat("Number of matches found: ", nummatch, "\n")
    cat("Total score of matches: ", ab, "\n")
    cat("Average score: ", ac , "\n")
    cat("\n")
  }
  
  ## Update score
  if (is.nan(ac)){
    tcga_coad_avg_chr1@elementMetadata@listData[["score"]][b] <- 0
  } else {
    tcga_coad_avg_chr1@elementMetadata@listData[["score"]][b] <- ac
  }
  
  ## checkpoints
  if (b == 100000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 200000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 300000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 400000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 500000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 600000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 700000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 800000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 900000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1000000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1100000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1200000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1300000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1400000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1500000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1600000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1700000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1800000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 1900000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  if (b == 2000000){save.image("~/atac/TCGAatac/TCGAatac.RData")}
  
} # end for (b in 1:num)
    

```


Functions
```{r}


```

Specify your input files
```{r}

# line_replicate$bam
# line_replicate$bai
# line_replicate$num.reads
# line_replicate$all.reads
# line_replicate$open.reads

#### SNU61 WT01 Replicate 1 ####
snu61_r1 <- list()
snu61_r1$bam <- "/home/ubuntu1/atac/snu61/wt01/dp_bam/test1.bam"
snu61_r1$bai <- "/home/ubuntu1/atac/snu61/wt01/dp_bam/test1.bam.bai"
snu61_r1$all.data <- granges(readGAlignmentPairs(bampath, index=idxpath, use.names=TRUE, param=NULL, with.which_label=FALSE, strandMode=1), on.discordant.seqnames="drop")
snu61_r1$num.reads <- length(snu61_r1$all.data)
snu61_r1$open.reads <- snu61_r1$all.data[width(snu61_r1$all.data) <= 100]
snu61_r1$num.open.reads <- length(open.reads)
snu61_r1$open.basecount <- basecount(windows=genome.windows, data=snu61_r1$open.reads, chrlist=good.uns)
snu61_r1$open.basecount@elementMetadata@listData[["score"]] <- (snu61_r1$open.basecount@elementMetadata@listData[["score"]] / snu61_r1[["num.reads"]]) * 1e+6
# peaks
snu61_r1$bed <- "/home/ubuntu1/atac/snu61/wt01/peaks_macs_m1/SNU61-WT-01-S3_S1.macs.m1_summits.bed"
snu61_r1$peaks <-  readBed(snu61_r1$bed, track.line = FALSE, remove.unusual = FALSE, zero.based = TRUE)


## Specify the Granges objects to turn into a list
glist <- GRangesList(snu61_r1[["open.reads"]], snu61_r2[["open.reads"]])

```


Standardize - transform CPM to num standard devs above or below population mean
```{r}

## Designate a set of noise peaks from which to determine background counts
N = 2.5e+4 # the number of background regions to generate
bins = genome.windows[seqnames(genome.windows) %in% good.uns]

## create a container for the standardized data
## define which genome windows do not overlap with peaks
## after enlarging peaks to uniform 20000 bp windows
notopen = gaps(reduce(trim(resize(snu61_r1[["peaks"]], fix = 'center', width = 20000))))

# retain only * (both) stranded data
notopen = notopen[strand(notopen) %in% '*']

# this finds the indices of 100 bp windows overlapping the set of noise ranges.
bgoverI = subjectHits(findOverlaps(notopen, bins)) 

# sets the seed for random number selection.
set.seed(138)

# this samples N of the noise regions for use downstream
bgseeds = sort(bgoverI[sample(seq(1,length(bgoverI),1),N)])

# this models a set of noise peaks whose centers are the regions we sampled 
# above, and whose widths are randomly distributed over the mean and sd of the
# log2 widths of the true peaks list. The log2 widths of the peaks approximates
# a normal distribution.
bgpeaks = trim(resize(bins[bgseeds],width = 2^(rnorm(N, mean = mean(log2(width(snu61_r1[["peaks"]]))),sd =sd(log2(width(snu61_r1[["peaks"]]))))),fix = 'center'))

# reduce overlapping peaks to a single peak
bgpeaks = reduce( 
    bgpeaks[!as.logical( countOverlaps( bgpeaks, snu61_r1[["peaks"]]))])



```


** Standardization -> transform the coverage values in CPM to the number of standard deviations above or below population mean **
```{r, error = FALSE, warning = FALSE, echo = TRUE}

#### the reason the loop was so slow
### is that its supposed to be run on a GRANGES LIST
### not every variable from a granges object
### lol

# Now, we need to measure the mean and standard deviation of reads within this
# set of background regions for each timepoint.

bgmeans = NULL # container for measured means
bgsds = NULL # container for measured standard deviations
openmeans = NULL # container for the measured open means
opensds = NULL # container for the measured open sds
zscores = list() # container for the calculated z-scores
bgzmeans = NULL # container for the standardized means
bgzsds = NULL # container for the standardized standard deviations
openzmeans = NULL # container for the standardized open means
openzsds = NULL # container for the standardized open sds

# Find overlaps between scores overlapping with a noise peak
test <- GenomicRanges::findOverlaps(bgpeaks, bins)
tidx <- test@to
ah <- GenomicRanges::score(snu61_r1[["open.basecount"]][tidx])

# Find scores for real peaks
test2 <- GenomicRanges::findOverlaps(snu61_r1[["peaks"]], bins)
tidx2 <- test2@to
ah2 <- GenomicRanges::score(snu61_r1[["open.basecount"]][tidx2])

bgoverscores <- ah
openoverscores <- ah2

bgmean = mean( bgoverscores) # calculates the mean of these scores
bgsd = sd( bgoverscores) # calculates the standard deviation of these scores


for(i in 1 : length(snu61_r1[["open.basecount"]]))
{





	bgmeans[i] = bgmean # assigns the mean to our initialized object

	bgsds[i] = bgsd # assigns the sd to our initialized object

  openmeans[i] = mean( openoverscores) # calculates the mean of the open scores
 
  opensds[i] = sd( openoverscores) # calculates the mean of the open sds
  
  cat("i")
  # populates a new variable with the scores
	znorm = GenomicRanges::score(snu61_r1[["open.basecount"]][i])
	cat("j")
	# calculates the zscore 
  znorm = ( znorm - bgmean) / bgsd
  cat("k")
  # populates our initialized object with the vector
  cat("l")
	zscores[[i]] = znorm
  # of z-scores for i-th timepoint
  
	cat("m")
	bgz = znorm[subjectHits( GenomicRanges::findOverlaps( bgpeaks, bins))]
    # gets the new calculated z-scores overlapping the noise peaks
  
	cat("n")
	openz = znorm[subjectHits( GenomicRanges::findOverlaps( snu61_r1[["peaks"]], bins))]
    # gets the new calculated z-scores overlapping the open peaks
  
	cat("o")
	bgzmeans[i] = mean( bgz) # populates our initialized object with the z mean
	cat("p")
	bgzsds[i] = sd( bgz) # populates our initialized object with the z sd
	cat("q")
  openzmeans[i] = mean( openz) # populates our initialized object with z mean
  # for open regions
  cat("r")
  openzsds[i] = sd( openz) # populates our initialized object with the z sd
  # for open regions
}






# what does this do to the data?
##################
initial.mean = unlist( lapply( wt.open, function( x) mean( score( x))))
zscore.mean = unlist( lapply( zscores, function( x) mean( x)))

stripchart(
    list( initial.mean, zscore.mean, bgmeans, bgzmeans, openmeans, openzmeans), 
    vertical = TRUE, pch = 19, col = 'blue', method = 'jitter', las = 1, 
    xlab = '', xaxt = 'n', ylab = 'mean score per timepoint')

mtext(side = 1, at = c(1:6), 
      c( 'CPM.all', 'Z.all','BG.CPM', 'BG.Z', 'OPEN.CPM','OPEN.Z'))

boxplot(
    list( initial.mean, zscore.mean, bgmeans, bgzmeans, openmeans, openzmeans), 
    add = TRUE, xaxt = 'n', yaxt = 'n')

```


The new z-scores can be appended to the *wt.open* object as a score and used for further analysis. Note, the boxplot above is meant to highlight how the average values of the scores change with this normalization. It is important to keep in mind that the effective units for the CPM values are in counts per million, whereas the z-score units are in standard deviations above the mean.


```{r}
bam <- granges(readGAlignmentPairs(bampath, index=idxpath, use.names=TRUE, param=NULL, with.which_label=FALSE, strandMode=1))

all.data <- granges(bam, on.discordant.seqnames="drop")

#### Read in the paired end bam file(s) as GAlingments
bam <- readGAlignmentPairs(bampath, index=idxpath, use.names=TRUE, param=NULL, with.which_label=FALSE, strandMode=1)

#### Convert the GAlignments to GRanges
all.data <- granges(bam, on.discordant.seqnames="drop")

### Get the total number of reads in the Granges object, this will be used as the denominator for CPM normalization
total.reads = length(all.data)
total.reads
```




